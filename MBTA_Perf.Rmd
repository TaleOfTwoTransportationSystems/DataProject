---
title: "MBTA Performance Data"
author: "Shawn Connor, Jeff Cunningham, Danielle Feng and Varuni Gang"
date: "May 4, 2016"
output: html_document
---
#### _CSCI E-107 Final Project_

### Overview and Motivation
asdf
from proposal:
The MBTA is the greater Boston area’s traditional public transit system with over 1 million riders per typical weekday. It is comprised of subway trains, longer reach commuter trains, buses and ferries. Since 2009, the MBTA has made available a large amount of data regarding trips on the system, including alerts. The real time alerts are scraped and then Tweeted by CodeForBoston.

Hubway is a growing bike sharing system implemented in Boston, Brookline, Cambridge, and Somerville. Users of the Hubway system range from young to old and live in various parts of the Greater Boston area. Users may rent bikes casually, or register for commutes. 

To our knowledge, there has been no previous analysis on the intersection of ridership of the MBTA and Hubway systems, both of which are deeply integrated into Boston’s transit system. Our project aims to related the trends in usage in a combined analysis of both transport systems. 

### Related work
asdf

* https://github.com/nsfm/kgk-mbta
* https://mbtaviz.github.io/
* https://api.rpubs.com/shimolu523/

### Initial Questions
asdf
from proposal:

* How much of a delay is there between a slow-down and an alert?  
* How much does ridership slow when there is an alert? Are alerts associated with all (most? some?) detected slowdown events?
* Is there a marked change in MBTA ridership when Hubway stops for the winter or resumes in the spring?
* Does activity at Hubway stations increase when a nearby subway train arrives? 
* How do MBTA slow-downs or alerts affect Hubway ridership?  

### Data
asdf
from proposal:

**MBTA Archive (2009-)**

* https://groups.google.com/forum/#!topic/massdotdevelopers/3J6EYlqWghY
* http://www.mbta.com/gtfs_archive/archived_feeds.txt

**Hubway Data (2011-2013)**

* http://hubwaydatachallenge.org/

**MBTA Alerts Twitter Feed (last 3200 tweets)**

* https://twitter.com/mbta_alerts
* https://twitter.com/mbta?lang=en
* https://cran.r-project.org/web/packages/twitteR/index.html
* http://bigcomputing.blogspot.com/2016/02/the-twitter-r-package-by-jeff-gentry-is.html
* May ask @CodeForBoson to download their entire feed.

**NOAA (last 5 years)**
* http://w2.weather.gov/climate/index.php?wfo=box

### Revised Questions
asdf

### Code

Load Libraries:

```{r Load_Libraries, warning=FALSE, message=FALSE}
library(dplyr)
library(jsonlite)
library(lubridate)
library(readr)
library(tidyr)
library(leaflet)
library(ggplot2)
library(twitteR) #masks id, location from dplyr
library(stringr)
library(ggmap)
library(maps)
library(mapproj)
library(rworldmap)
library(dygraphs)
library(grid)
library(gridExtra)
```

Some things we hard code:

```{r Hardcoded_Stuff}
# API information for the real-time feed
TKeyJeff <- "?api_key=tNprgYF1K027zEIVluAkCw"
#TKeyAPIDoc <- "?api_key=wX9NwuHnZU2ToO7GmGR9uw"
TRouteURL <- "http://realtime.mbta.com/developer/api/v2/stopsbyroute"
TTravelURL <- "http://realtime.mbta.com/developer/api/v2.1/traveltimes"
TFormat <- "&format=json"

startTime <- as.POSIXct("2016-01-25 04:00:00") # the start date of the class -- does affect how many archives are needed

TArchiveURLs <- c("http://www.mbta.com/uploadedfiles/MBTA_GTFS.zip",
                  "http://www.mbta.com/gtfs_archive/20151211.zip") # first is current archive; the rest are father back in time

# generated from twitter's website
consumer_key <- 'bpCAcAY27kfpSyOAOFXNP2PsO'
consumer_secret <- '5skjmU5FgWUA77PI4OwuBLcmv3Rr03xEKZQoG0FJJbI0wt3oMa'
access_token <- '111824999-KVpkYnMt3MZU2Bfxl9lcHZfMvdF5pYZiHQqSonE6'
access_secret <- 'Ib5N3qKxZ7CT1TuQeznHv6XobdCmjZkSVTESkVj7TwVZm'

weather<-read.csv("https://www.ncei.noaa.gov/orders/cdo/729412.csv")
```

asdf Google realtime performance blah blah

```{r Pull_Performance_Data}
RedLineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Red", sep=""))[[1]]
```

Here are the connections for some lines we're not using yet:
```{r echo=FALSE}
# Routes we're not using yet

 MattapanLineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Mattapan", sep=""))[[1]]
 GreenBLineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Green-B", sep=""))[[1]]
 GreenCLineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Green-C", sep=""))[[1]]
 GreenDLineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Green-D", sep=""))[[1]]
 GreenELineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Green-E", sep=""))[[1]]
 BlueLineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Blue", sep=""))[[1]]
 OrangeLineRoute <- fromJSON(paste(TRouteURL, TKeyJeff, TFormat, "&route=Orange", sep=""))[[1]]
```

```{r}
# Create a list of all stop pairs; the Route info does not cotain sufficient information separate the Ashmont (a) and
# Braintree (b) lines. Digging this out of the schedule archive is possible but would have taken longer. Start with Southbound...
south_main <- data.frame(
  stop_id = c("70061","70063","70065","70067","70069","70071","70073","70075","70077","70079","70081"),
  next_stop = c("70063","70065","70067","70069","70071","70073","70075","70077","70079","70081","70083"))
south_a <- data.frame(
  stop_id = c("70083","70085","70087","70089","70091"),
  next_stop = c("70085","70087","70089","70091","70093"))
south_b <- data.frame(
  stop_id = c("70083","70095","70097","70099","70101","70103"),
  next_stop = c("70095","70097","70099","70101","70103","70105"))

# Repeat for Northbound...
north_main <- data.frame(
  stop_id = c("70084","70082","70080","70078","70076","70074","70072","70070","70068","70066","70064"),
  next_stop = c("70082","70080","70078","70076","70074","70072","70070","70068","70066","70064","70061"))
north_a <- data.frame(
  stop_id = c("70094","70092","70090","70088","70086"),
  next_stop = c("70092","70090","70088","70086","70084"))
north_b <- data.frame(
  stop_id = c("70105","70104","70102","70100","70098","70096"),
  next_stop = c("70104","70102","70100","70098","70096","70084"))

# Then rbind everything together.
distinct_stop_pairs <- rbind(south_main, south_a, south_b, north_main, north_a, north_b)
distinct_stop_pairs_full <- distinct_stop_pairs

```



```{r Fetch_Travel_Times}
# The following can be skipped if "train_travel_times.csv" is present in the working directory
if(length(ls(pattern="travel_times")) > 0) {
    # do nothing - we already have the data in the environment
} else if (file.exists("train_travel_times.csv.gz")) {
    print("Loading previously generated data.")
    travel_times <- read_csv("train_travel_times.csv.gz") # can skip MBTA queries and load this instead
    if(names(travel_times[1])=="") {
        travel_times <- select(travel_times, 2:ncol(travel_times)) # remove our nameless index column
    }
} else {
    print("Requesting data from realtime.mbta.com...")
    # create a holding frame for the data; we do this outside the loops so that it will persist.
    travel_times <- data.frame(direction=as.numeric(character()),
                        dep_dt=as.POSIXct(character()), 
                        arr_dt=as.POSIXct(character()), 
                        travel_time_sec=as.numeric(character()),
                        benchmark_travel_time_sec=as.numeric(character()),
                        from_stop=character(), 
                        to_stop=character()) 
    
    # How many seven day periods from start to now?
    numWeeks <- as.integer(unclass(now() - startTime)/7)
    
    # The outer loop cycles through every distinct pair of stops.
    for(j in 1:nrow(distinct_stop_pairs)) {
      from_j <- distinct_stop_pairs[j,]$stop_id
      to_j <- distinct_stop_pairs[j,]$next_stop
      fromStop <- paste("&from_stop=", from_j, sep="")
      toStop <- paste("&to_stop=", to_j, sep="")
      print(paste("Requesting", from_j, "to", to_j))
      
      # The inner loop cycles through each week of interest.  
      for(i in 0:numWeeks) {
        fromTime <- paste("&from_datetime=", as.numeric(startTime + days(i * 7)), sep="")
        toTime <- paste("&to_datetime=", as.numeric(startTime + days(i * 7) + days(7) - minutes(1)), sep="")
        TRequest <- paste(TTravelURL, TKeyJeff, TFormat, fromStop, toStop, fromTime, toTime, sep="")
        foo <- fromJSON(TRequest)[[1]]
        
        # Assuming we get a result back, we process it within the
        # inner loop, reformatting columns and dropping any we don't
        # plan to use. We then append it to travel_times.
        if (length(foo) > 0) {
          bar <- foo %>%
            mutate(from_stop = from_j,
              to_stop = to_j,
              dep_dt = as.POSIXct(as.integer(dep_dt), origin="1970-01-01"),
              arr_dt = as.POSIXct(as.integer(arr_dt), origin="1970-01-01"),
              travel_time_sec = as.numeric(travel_time_sec),
              benchmark_travel_time_sec = as.numeric(benchmark_travel_time_sec)) %>%
            select(-route_id, -contains("threshold"))
          travel_times <- rbind(travel_times, bar)
        } else {
          print(paste("Nothing returned for", fromStop, "to", toStop, "during period", fromTime, "-", toTime))
        }
        Sys.sleep(2) #slow down a bit
      }
    }
    
    # splitting date & time
    travel_times <- mutate(travel_times, dep_d=as.Date(dep_dt), 
                                                 dep_t=format(as.POSIXct(dep_dt), format="%H:%M:%S"), 
                                                 arr_d=as.Date(arr_dt), 
                                                 arr_t=format(as.POSIXct(arr_dt), format="%H:%M:%S"))
    # adding parent_station_name, lat and lon
    travel_times <- bind_rows(RedLineRoute$stop[1][[1]], RedLineRoute$stop[2][[1]]) %>% 
                        select(stop_id, parent_station_name, stop_lat, stop_lon) %>% 
                        mutate(stop_id=as.integer(stop_id)) %>% 
                        rename(to_stop = stop_id, to_name = parent_station_name, to_lat = stop_lat, to_lon = stop_lon) %>% 
                        inner_join(travel_times, by="to_stop")
    travel_times <- bind_rows(RedLineRoute$stop[1][[1]], RedLineRoute$stop[2][[1]]) %>% 
                        select(stop_id, parent_station_name, stop_lat, stop_lon) %>% 
                        mutate(stop_id=as.integer(stop_id)) %>% 
                        rename(from_stop = stop_id, from_name = parent_station_name, from_lat = stop_lat, from_lon = stop_lon) %>% 
                        inner_join(travel_times, by="from_stop")
    travel_times <- arrange(travel_times, direction, dep_dt)
    
    z <- gzfile("train_travel_times.csv.gz")
    write.csv(travel_times, z) #so others don't need to pull the data again
}
```

asdf This is the data we were going to orginally compare to Hubway, etc. but it's only _schedule_ data! blah blah

```{r Pull_Archive_Data, cache=TRUE, warning=FALSE}
for(i in 1:length(TArchiveURLs)) {
    if(file.exists(basename(TArchiveURLs[i]))) {
        print(paste("Using existing", basename(TArchiveURLs[i])))
    } else {
        download.file(TArchiveURLs[i], destfile=basename(TArchiveURLs[i]))
    }
    unzip(basename(TArchiveURLs[i]), exdir=strsplit(basename(TArchiveURLs[i]), "\\.")[[1]][1], overwrite=FALSE)
}

# The following is fixed for two archives; should be loop based on length of TArchivesURLs
setwd(strsplit(basename(TArchiveURLs[1]), "\\.")[[1]][1])

# Get schedule data:
Tarchive_cal <- read_csv("calendar.txt") %>% mutate(zip_file=basename(getwd()))
Tarchive_calDates <- read_csv("calendar_dates.txt")
Tarchive_trips <- read.csv("trips.txt")
Tarchive_stopTimes <- read.csv("stop_times.txt")
Tarchive_stops <- read.csv("stops.txt")

# OK, as a first step, let's trim back the Tarchive tables to just the subway (RTL) data:
Tarchive_cal <- filter(Tarchive_cal, grepl("RTL", service_id))
Tarchive_calDates <- filter(Tarchive_calDates, grepl("RTL", service_id)) # exception_type; 1=added; 2=removed
Tarchive_trips <- filter(Tarchive_trips, grepl("RTL", service_id))
Tarchive_stopTimes <- filter(Tarchive_stopTimes, trip_id %in% Tarchive_trips$trip_id)

setwd("..")

# Loop, please:
setwd(strsplit(basename(TArchiveURLs[2]), "\\.")[[1]][1])

Tarchive_cal2 <- read_csv("calendar.txt") %>% mutate(zip_file=basename(getwd()))
Tarchive_calDates2 <- read_csv("calendar_dates.txt")
Tarchive_trips2 <- read.csv("trips.txt")
Tarchive_stopTimes2 <- read.csv("stop_times.txt")

# trim2 -- dealing with multiple archive files really cries out for a function here, doesn't it
Tarchive_cal2 <- filter(Tarchive_cal2, grepl("RTL", service_id))
Tarchive_calDates2 <- filter(Tarchive_calDates2, grepl("RTL", service_id)) # exception_type; 1=added; 2=removed
Tarchive_trips2 <- filter(Tarchive_trips2, grepl("RTL", service_id))
Tarchive_stopTimes2 <- filter(Tarchive_stopTimes2, trip_id %in% Tarchive_trips$trip_id)

# combine our archives
Tarchive_cal <- bind_rows(Tarchive_cal, Tarchive_cal2)
Tarchive_calDates <- bind_rows(Tarchive_calDates, Tarchive_calDates2)
Tarchive_trips <- bind_rows(Tarchive_trips, Tarchive_trips2)
Tarchive_stopTimes <- bind_rows(Tarchive_stopTimes, Tarchive_stopTimes2)

setwd("..")

rm(Tarchive_cal2)
rm(Tarchive_calDates2)
rm(Tarchive_trips2)
rm(Tarchive_stopTimes2)

# Convert the dates:
Tarchive_cal <- mutate(Tarchive_cal, start_date=as.Date(as.character(start_date), format="%Y%m%d", origin="1970-01-01"), 
                                     end_date=as.Date(as.character(end_date), format="%Y%m%d", origin="1970-01-01"))
Tarchive_calDates <- mutate(Tarchive_calDates, date=as.Date(as.character(date), format="%Y%m%d", origin="1970-01-01"))

# Now, loop through each day between the start date and today,
# for each day, get the relevant service_ids and,
# find the corresponding trip_ids, then
# pull all the corresponding train arrival and departure times
schedule_dataset <- data.frame()
for(i in 0:(as.integer(unclass(now() - startTime)))) {
    iDate <- as.Date(startTime+days(i))
    
    #service_ids
    todaysServices <- filter(Tarchive_cal, start_date<=iDate & end_date>=iDate) %>%
        select(service_id) %>%
        distinct()

    #remove exceptions
    if(iDate %in% Tarchive_calDates$date) {
        servicesRemoved <- unique(filter(Tarchive_calDates, date==iDate & exception_type==2)[[1]])
        if(length(servicesRemoved)>1) {
            todaysServices <- filter(todaysServices, !service_id %in% servicesRemoved)
        }
    }
    
    #remove remaining regularly scheduled services that don't match this day of the week
    if(wday(iDate)==1) {
        todaysServices <- filter(todaysServices, grepl("Sunday", service_id))
    } else if(wday(iDate)==7) {
        todaysServices <- filter(todaysServices, grepl("Saturday", service_id))
    } else {
        todaysServices <- filter(todaysServices, grepl("Weekday", service_id))
    }
        
    #add exceptions
    if(iDate %in% Tarchive_calDates$date) {
        servicesAdded <- filter(Tarchive_calDates, date==iDate & exception_type==1) %>% 
                         select(service_id) %>% 
                         distinct()
        if(nrow(servicesAdded)>1) {
            todaysServices <- bind_rows(todaysServices, servicesAdded)
        }
    }
        
    #trip_ids
    todaysTrips <- filter(Tarchive_trips, service_id %in% todaysServices$service_id) %>% 
                  filter(route_id=="Red") %>% 
                  distinct()
#     print(paste(i, "; Date: ", iDate, "; # Services: ", nrow(todaysServices), "; # Trips: ", nrow(todayTrips), 
#                 "; Exception = ", (iDate %in% Tarchive_calDates$date), sep=""))

    #stop_times
    todaysStops <- filter(Tarchive_stopTimes, trip_id %in% todaysTrips$trip_id) %>% 
                   mutate(arrival_date=iDate, departure_date=iDate)
    
    schedule_dataset <- bind_rows(schedule_dataset, todaysStops)
}
```

We also want to pull what the MBTA calls "headways"; these track the time between departures at a given station. When trains are running late, headways exceed their benchmark targets. The root causes of slow service can probably be better picked apart from travel times and dwell times, but the eventual impact to riders is most cleanly seen in headways.
```{r Fetch_Headways}
# The following can be skipped if "train_headway_times.csv" is present in the working directory
if(length(ls(pattern="headway_times")) > 0) {
  # do nothing - we already have the data in the environment
} else if (file.exists("train_headway_times.csv.gz")) {
  print("Loading previously generated data.")
  headway_times <- read_csv("train_headway_times.csv.gz") # can skip MBTA queries and load this instead
  names(headway_times)[1] <- "index" # adding a name to our unnamed first column -- this column gets added by read_csv
}
else {
  print("Requesting data from realtime.mbta.com...")
  # create a holding frame for the data; we do this outside the loops so that it will persist.
  headway_times <- data.frame(direction=as.numeric(character()),
                              current_dep_dt=as.POSIXct(character()), 
                              previous_dep_dt=as.POSIXct(character()), 
                              headway_time_sec=as.numeric(character()),
                              benchmark_headway_time_sec=as.numeric(character()),
                              from_stop=character(), 
                              to_stop=character()) 
  
  # How many seven day periods from start to now?
  numWeeks <- as.integer(unclass(now() - startTime)/7)
  
  # The outer loop cycles through every distinct pair of stops.
  for(j in 1:nrow(distinct_stop_pairs)) {
    from_j <- distinct_stop_pairs[j,]$stop_id
    to_j <- distinct_stop_pairs[j,]$next_stop
    fromStop <- paste("&stop=", from_j, sep="")
    toStop <- paste("&to_stop=", to_j, sep="")
    print(paste("Requesting", from_j, "to", to_j))
    
    # The inner loop cycles through each week of interest.  
    for(i in 0:numWeeks) {
      fromTime <- paste("&from_datetime=", as.numeric(startTime + days(i * 7)), sep="")
      toTime <- paste("&to_datetime=", as.numeric(startTime + days(i * 7) + days(7) - minutes(1)), sep="")
      TRequest <- paste(THeadwaysURL, TKeyJeff, TFormat, fromStop, toStop, fromTime, toTime, sep="")
      foo <- fromJSON(TRequest)[[1]]
      
      # Assuming we get a result back, we process it within the
      # inner loop, reformatting columns and dropping any we don't
      # plan to use. We then append it to travel_times.
      if (length(foo) > 0) {
        bar <- foo %>%
          mutate(from_stop = from_j,
                 to_stop = to_j,
                 current_dep_dt = as.POSIXct(as.integer(current_dep_dt), origin="1970-01-01"),
                 previous_dep_dt = as.POSIXct(as.integer(previous_dep_dt), origin="1970-01-01"),
                 headway_time_sec = as.numeric(headway_time_sec),
                 benchmark_headway_time_sec = as.numeric(benchmark_headway_time_sec)) %>%
          select(-route_id, -contains("threshold"))
        headway_times <- rbind(headway_times, bar)
      } else {
        print(paste("Nothing returned for", fromStop, "to", toStop, "during period", fromTime, "-", toTime))
      }
      Sys.sleep(2) #slow down a bit
    }
  }
  
  # splitting date & time
  headway_times <- mutate(headway_times, current_dep_d=as.Date(current_dep_dt), 
                          current_dep_t=format(as.POSIXct(current_dep_dt), format="%H:%M:%S"), 
                          previous_dep_d=as.Date(previous_dep_dt), 
                          previous_dep_t=format(as.POSIXct(previous_dep_dt), format="%H:%M:%S"))
  # adding parent_station_name, lat and lon
  headway_times <- bind_rows(RedLineRoute$stop[1][[1]], RedLineRoute$stop[2][[1]]) %>% 
    select(stop_id, parent_station_name, stop_lat, stop_lon) %>% 
    mutate(stop_id=as.integer(stop_id)) %>% 
    rename(to_stop = stop_id, to_name = parent_station_name, to_lat = stop_lat, to_lon = stop_lon) %>% 
    inner_join(headway_times, by="to_stop")
  headway_times <- bind_rows(RedLineRoute$stop[1][[1]], RedLineRoute$stop[2][[1]]) %>% 
    select(stop_id, parent_station_name, stop_lat, stop_lon) %>% 
    mutate(stop_id=as.integer(stop_id)) %>% 
    rename(from_stop = stop_id, from_name = parent_station_name, from_lat = stop_lat, from_lon = stop_lon) %>% 
    inner_join(headway_times, by="from_stop")
  headway_times <- arrange(headway_times, direction, current_dep_dt)
  
  z <- gzfile("train_headway_times.csv.gz")
  write.csv(headway_times, z) #so others don't need to pull the data again
}

```

Before we can work with the travel time or headways data, we need ot clean up some data types.
```{r}
travel_times$X <- NULL
travel_times$direction <- as.character(travel_times$direction)
travel_times$from_stop <- as.character(travel_times$from_stop)
travel_times$to_stop <- as.character(travel_times$to_stop)
travel_times$dep_dt <- as.POSIXct(travel_times$dep_dt, tz="EST")
travel_times$arr_dt <- as.POSIXct(travel_times$arr_dt, tz="EST")
travel_times$dep_d <- as.POSIXct(travel_times$dep_d, tz="EST")
travel_times$arr_d <- as.POSIXct(travel_times$arr_d, tz="EST")

headway_times$X <- NULL
headway_times$direction <- as.character(headway_times$direction)
headway_times$from_stop <- as.character(headway_times$from_stop)
headway_times$to_stop <- as.character(headway_times$to_stop)
headway_times$current_dep_dt <- as.POSIXct(headway_times$current_dep_dt, tz="EST")
headway_times$previous_dep_dt <- as.POSIXct(headway_times$previous_dep_dt, tz="EST")
headway_times$current_dep_d <- as.POSIXct(headway_times$current_dep_d, tz="EST")
headway_times$previous_dep_d <- as.POSIXct(headway_times$previous_dep_d, tz="EST")

# Add a column for how far off of benchmark each value is. In theory slowdowns are transferred
# through the system linearly, so one minute of delay is one minute of delay.
travel_times$time_delta <- travel_times$travel_time_sec - travel_times$benchmark_travel_time_sec
headway_times$time_delta <- headway_times$headway_time_sec - headway_times$benchmark_headway_time_sec

# While we're at it, we'll also calculate "lateness" for headways; how many seconds (if any)
# the departure exceeded it's benchmark headway time.

headway_times$lateness <- headway_times$headway_time_sec - headway_times$benchmark_headway_time_sec
headway_times[headway_times$lateness < 0,]$lateness <- 0

# Add a column for the "effective service date", so that late-night trains can be easily
# counted as part of the previous day.
travel_times$dt <- as.POSIXct(trunc(travel_times$dep_dt - seconds(14400), units = "days"))
headway_times$dt <- as.POSIXct(trunc(headway_times$current_dep_dt - seconds(14400), units = "days"))

# Adding a convenient reference column for whether the day is a weekend or not, since
# train schedules are very different. This also makes it very convenient to replace the
# contents of this column if, in future work, one wanted to replace this with an actual
# schedule reference (weekday holidays sometimes run weekend schedules)
travel_times$is_weekend <- as.POSIXlt(travel_times$dt)$wday %in% c(0,6)
headway_times$is_weekend <- as.POSIXlt(headway_times$dt)$wday %in% c(0,6)

```

As a final table-modification step, create a simple ordered list of stops with relevant properties, both as a lookup and so stops can appear in order in visualizations. It will still produce odd behavior around the Red Line's fork, but more advanced visualizations will take this into account. We join this table to our headway and travel time data.
```{r stop_lookup}
stop_sequence <- rbind(
# Southbound
  RedLineRoute$stop[[1]] %>%
  arrange(as.integer(stop_order)) %>%
  mutate(stop_seq = row_number(), heading = "Southbound") %>%
  select (stop_id, stop_name, parent_station_name, heading, stop_seq),
# Northbound
  RedLineRoute$stop[[2]] %>%
  arrange(as.integer(stop_order)) %>%
  mutate(stop_seq = row_number(), heading = "Northbound") %>%
  select (stop_id, stop_name, parent_station_name, heading, stop_seq))

headway_times <- headway_times %>%
  mutate(dep_time = current_dep_dt - dt) %>%
  left_join(.,stop_sequence, by=c("from_stop" = "stop_id"))

travel_times <- travel_times %>%
  mutate(dep_time = dep_dt - dt) %>%
  left_join(.,stop_sequence, by=c("from_stop" = "stop_id"))
```

A simple scatter plot of train departures from Porter Square heading inbound over time, to demonstrate what the data looks like.
```{r vis_train_departures}
plot(as.numeric(travel_times[travel_times$from_stop == "70065",]$dep_dt - travel_times[travel_times$from_stop == "70065",]$dt,unit = 'mins'),
     travel_times[travel_times$from_stop == "70065",]$dt,
     main="train departures from Porter Square heading inbound",
     xlab="Minutes since midnight", ylab = "Date of Trip", pch=".")
```

Here's one using headways, color-coding lateness (more on this later!):
```{r vis_headway_lateness}
plot(as.numeric(headway_times[headway_times$from_stop == "70065",]$current_dep_dt - headway_times[headway_times$from_stop == "70065",]$dt,unit = 'mins'),
     headway_times[headway_times$from_stop == "70065",]$dt,
     main="Departures from Porter Square heading inbound\n color-coded by headway lateness",
     xlab="Minutes since midnight", ylab = "Date of Trip", pch=".", col = heat.colors(headway_times[headway_times$from_stop == "70065",]$lateness))

```

Here we look at the times between trains by time of day. We restrict the data to only southbound weekday trains, so as to avoid mixing unrelated data in the same plot.
```{r vis_headway_weekday_southbound}
ggplot(headway_times %>% filter(is_weekend == FALSE, direction == "0"), aes(x = as.numeric(dep_time, units="hours"), y = time_delta)) +
  geom_point(alpha=0.1) +
  xlab("Hours (24+ is past midnight)") +
  ylab("Seconds from Benchmark") +
  ggtitle("Times between trains by time of day, weekday Southbound")
```


Boxplot of times between trains by station, weekday Southbound.
```{r vis_time_delta_boxplot} 
boxplot(time_delta~parent_station_name,
     data = headway_times %>% filter(is_weekend == FALSE, direction == "0"),
     main="times between trains by station, weekday Southbound",
     xlab="Stop Sequence", ylab = "wait time (seconds)", pch=".", ylim=c(-800, 1600))

# Boxplot of times between trains by station, weekday Northbound.
boxplot(time_delta~stop_seq,
        data = headway_times %>% filter(is_weekend == FALSE, direction == "1"),
        main="times between trains by station, weekday Southbound",
        xlab="Stop Sequence", ylab = "wait time (seconds)", pch=".", ylim=c(-800, 1600))

# density plot of times between trains by station.
headway_plots <- list()
headway_plots[[1]] <- ggplot(headway_times %>% filter(direction == "0", is_weekend == FALSE), aes(x=time_delta)) +
  geom_density(aes(group = parent_station_name, colour= parent_station_name, fill= parent_station_name), alpha=0.2) +
  ggtitle("Weekday, Southbound") +
  xlim(-1200,2000) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title=element_blank(),
        legend.key.size=unit(0.3, "cm"),
        legend.text=element_text(size=6),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        plot.title = element_text(size = 10))

headway_plots[[2]] <- ggplot(headway_times %>% filter(direction == "1", is_weekend == FALSE), aes(x=time_delta)) +
  geom_density(aes(group = parent_station_name, colour= parent_station_name, fill= parent_station_name), alpha=0.2) +
  ggtitle("Weekday, Northbound") + 
  xlim(-1200,2000) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title=element_blank(),
        legend.key.size=unit(0.3, "cm"),
        legend.text=element_text(size=6),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        plot.title = element_text(size = 10))

headway_plots[[3]] <- ggplot(headway_times %>% filter(direction == "0", is_weekend == TRUE), aes(x=time_delta)) +
  geom_density(aes(group = parent_station_name, colour= parent_station_name, fill= parent_station_name), alpha=0.2) +
  ggtitle("Weekend, Southbound") +
  xlim(-1200,2000) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title=element_blank(),
        legend.key.size=unit(0.3, "cm"),
        legend.text=element_text(size=6),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        plot.title = element_text(size = 10))

headway_plots[[4]] <- ggplot(headway_times %>% filter(direction == "1", is_weekend == TRUE), aes(x=time_delta)) +
  geom_density(aes(group = parent_station_name, colour= parent_station_name, fill= parent_station_name), alpha=0.2) +
  ggtitle("Weekend, Northbound") +
  xlim(-1200,2000) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title=element_blank(),
        legend.key.size=unit(0.3, "cm"),
        legend.text=element_text(size=6),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        plot.title = element_text(size = 10))
  
grid.arrange(headway_plots[[1]], headway_plots[[2]],headway_plots[[3]],headway_plots[[4]], ncol=2, left="Type of Day", top="Heading")
grid.rect(gp=gpar(fill=NA, col="gray"))

# And a simple plot of the densities of travel times for Northbound trains of weekdays, all times of day.
ggplot((travel_times %>% filter(direction == 1, is_weekend == FALSE)), aes(x=travel_time_sec)) +
  geom_density(aes(group = parent_station_name, colour= parent_station_name, fill= parent_station_name), alpha=0.2) +
  ggtitle("Travel times for Northbound trains of weekdays, by departing station") +
  xlim(0, 200) + ylim(0, .25)

# Lets take a look at service quality. One sensible metric would be how long pasengers are 
# waiting on platforms for trains beyond how long they "should" be waiting per normal service.
# In our data this can be thought of as the difference between the actual observed times
# and the benchmark times provided by the MBTA. However, we only look for cases where this
# number is positive; the MBTA gets no extra credit for early trains! This isn't because
# we're mean spirited, it's because faster-than-expected headways are indistinguishable from
# just happening to get to the platform at the right time to a typical rider, and because 
# faster-than-expected headways are often the result of backup cause by slowness earlier in
# the day.

# Here's a simple density plot of ALL observed lateness (on-time or early headways removed)
# to give an idea of what is typical
ggplot(headway_times %>% filter(lateness > 0), aes(x=lateness)) +
  geom_density(aes(colour="All Trains", fill="All Trains"), alpha=0.5) +
  ggtitle("Total distribution of Lateness (seconds)") +
  xlim(0,2000) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title=element_blank(),
        legend.key.size=unit(0.3, "cm"),
        legend.text=element_text(size=6),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        plot.title = element_text(size = 10))

# Lets see if there are broad patterns by type of day or direction of travel.
ggplot(headway_times %>% filter(lateness > 0) %>% mutate(is_weekend = ifelse(is_weekend, "Weekend", "Weekday")), aes(x=lateness)) +
  geom_density(aes(group=paste(is_weekend, heading), colour=paste(is_weekend, heading), fill=paste(is_weekend, heading)), alpha=0.3) +
  ggtitle("Total distribution of Lateness (seconds)") +
  xlim(0,2000) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title=element_blank(),
        legend.key.size=unit(0.3, "cm"),
        legend.text=element_text(size=6),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        plot.title = element_text(size = 10))

# Interesting; it looks like the MBTA's expected benchmarks are pretty good, though the Weekday
# Southbound trains tend to have shorter lateness events, and Weekend Northbound they tend to be
# longer. NOTE, however, that we can't say that weekend Northbound tends to be late moreoften,
# because we through out anything that wasn't lateness already.

seconds_of_day <- data.frame(interval_start_hour = seq(0,26,1), hour_start = seq(0, 60*60*26, 60*60),
hour_end = seq(60*60, 60*60*27, 60*60))

count_of_days <- headway_times %>%
  group_by(is_weekend, dt) %>%
  summarize(count = 1) %>%
  mutate(weekend = ifelse(is_weekend, "Weekend", "Weekday")) %>%
  group_by(weekend) %>%
  summarize(days_observed = sum(count))

total_lateness <- headway_times %>%
  filter(lateness > 0) %>%
  select(from_stop, parent_station_name, heading, is_weekend, current_dep_dt, dt, lateness) %>%
  mutate(lateness_start = current_dep_dt - lateness, stop_id = from_stop) %>%
  mutate(dep_t = as.numeric(current_dep_dt - dt, unit = "secs"), late_t = as.numeric(lateness_start - dt, unit = "secs")) %>%
  merge(.,seconds_of_day, all=TRUE) %>%
  filter((late_t > hour_start & late_t < hour_end) | (dep_t > hour_start & dep_t < hour_end) | (late_t < hour_start & dep_t > hour_end)) %>%
  mutate(eff_late_start = ifelse(late_t < hour_start, hour_start, late_t), eff_late_end = ifelse(dep_t > hour_end, hour_end, dep_t)) %>%
  mutate(eff_lateness = eff_late_end - eff_late_start, weekend = ifelse(is_weekend, "Weekend", "Weekday")) %>%
  group_by(interval_start_hour, stop_id, parent_station_name, heading, weekend) %>%
  summarize(total_lateness = sum(eff_lateness)) %>%
  left_join(.,count_of_days) %>%
  mutate(seconds_observed = (days_observed*60*60)) %>%
  select(-days_observed)

# Hey, that's cool! We can now compute how late the t was running for any arbitrary
# combination of hour-of-day, stop, heading, weekend/weekday, just by summing the
# seconds of observed lateness and deviding by the sum of seconds observed. This
# gives us a metric, "percent late", which we can think of as "for the entire time
# we observed the station, for what % of that time was a train past it's benchmark
# arrival time? So, for example:

total_lateness %>%
  group_by(parent_station_name, heading) %>%
  summarize(percent_late = sum(total_lateness)/sum(seconds_observed))

weekday_southbound <- total_lateness %>%
  filter(heading == "Southbound", weekend == "Weekday") %>%
  group_by(parent_station_name, interval_start_hour) %>%
  summarize(percent_late = sum(total_lateness)/sum(seconds_observed))

ggplot(weekday_southbound, aes(as.ordered(interval_start_hour), parent_station_name)) +
  geom_tile(aes(fill = percent_late), color = "white") +
  scale_fill_gradient(low = "white",high = "red")
```


asdf Alerts come in from Twitter via CodeForBoston blah blah

```{r Pull_Alerts}
# The following can be skipped if "red_line_tweets.csv" is present in the working directory
if (file.exists("red_line_tweets.csv") & file.exists("green_line_alert.csv")) {
    print("Loading previously generated data.")
    red_line_alert<- read_csv("red_line_tweets.csv") # can skip Twitter queries and load this instead
    green_line_alert <- read_csv("green_line_alert.csv")
} else {
    
    # authorizing twitter 
    setup_twitter_oauth(consumer_key = consumer_key, 
                        consumer_secret =  consumer_secret, 
                        access_token = access_token, 
                        access_secret = access_secret)
    
    # makes dataframe for results and gets specific features
    getSpecificTweetInformation <- function(x) {
        twListToDF(x) %>% 
            select(screenName, id, text, created, favoriteCount, retweetCount)
    }
    
    # Red Line Alerts user time line only 3200 hard limit
    Red_Line_Alerts_tweets <- userTimeline('Red_Line_Alerts', n=3200, includeRts = FALSE, excludeReplies = TRUE)
    
    # MattaPan Line Alerts user time line only 3200 hard limit
    highspeedalerts_tweets <- userTimeline('highspeedalerts', n=3200, includeRts = FALSE, excludeReplies = TRUE)
    
    # Green Line Alerts user time line only 3200 hard limit
    GreenLineAlerts_tweets <- userTimeline('GreenLineAlerts', n=3200, includeRts = FALSE, excludeReplies = TRUE)
    
    # For other twitter alerts: 
    # # MBTA user time line only 3200 hard limit
    # mbta_tweets <- userTimeline('MBTA', n=3200, includeRts = FALSE, excludeReplies = TRUE)
    # 
    # # MBTA Alerts user time line only 3200 hard limit
    # mbta_alerts_tweets <- userTimeline('mbta_alerts', n=3200, includeRts = FALSE, excludeReplies = TRUE)
    # 
    # # Orange Line Alerts user time line only 3200 hard limit
    # OrangeLineAlert_tweets <- userTimeline('OrangeLineAlert', n=3200, includeRts = FALSE, excludeReplies = TRUE)
    # 
    # # Blue Line Alerts user time line only 3200 hard limit
    # BlueLineAlerts_tweets <- userTimeline('BlueLineAlerts', n=3200, includeRts = FALSE, excludeReplies = TRUE)
    

    # Combining tweets from different twitter handles
    red_line_alert <- getSpecificTweetInformation(Red_Line_Alerts_tweets) %>% 
        union(getSpecificTweetInformation(highspeedalerts_tweets)) 
    
    # for green line alerts
    green_line_alert <- getSpecificTweetInformation(GreenLineAlerts_tweets)
    
    # write all to a csv
    write_csv(red_line_alert, "red_line_alert.csv") 
    write_csv(green_line_alert, "green_line_alert.csv") 
}

# tweet count and oldest and most recent tweet dates
red_line_alert %>% 
    group_by(screenName) %>% 
    summarise(num_of_tweets=n(), 
              oldest_date=min(as.Date.POSIXct(created)), 
              most_recent_date=max(as.Date.POSIXct(created)))
```

asdf

```{r Compare_Alerts_To_Performance}
# To relate to a data we already have is to add 
# these tweets as "arrival date" ~ "created" and then join them.
red_line_alert <- red_line_alert %>% 
    filter(created > startTime) %>%
    arrange(created) %>% 
    select(text, created, favoriteCount, retweetCount) %>% 
    mutate(arr_dt = created)

travel_times <- travel_times %>% 
    full_join(red_line_alert)

# To add tweets as a parameter for stops is by 
# pulling in stop names from the tweets and then mapping them to stop ids.

# First step is to pull in all the relevant stop ids from our full dataset
stop_ids <- c(travel_times$from_stop, travel_times$to_stop) %>% unique()

# Second step is get the actaul stop names for these stops
stop_names_codes <- Tarchive_stops %>% 
    filter(stop_id %in% stop_ids) %>% 
    select(stop_code, stop_name) %>% 
    unite(stop_code_name, stop_code, stop_name)

# Steps that I am taking to get the tweet-station pair
# 1. Pull in if the delay or issue is from a north_bound or south_bound or both trips
red_line_alert <- red_line_alert %>% 
    mutate(bounded = ifelse(grepl("northbound", text, ignore.case = TRUE), "northbound",
                            ifelse(grepl("southbound", text, ignore.case = TRUE), "southbound",
                                   ifelse(grepl("both ways|both direction", text, ignore.case = TRUE), "northbound_and_southbound", ""))))

# (side-step) level of severity ~ would be cool to draw a graph to see
# if severity increases with delay time or
# time series of severity increasing in the north/south bound trains
red_line_alert <- red_line_alert %>% 
    mutate(severity = ifelse(grepl("minor delay",text, ignore.case = TRUE), 1, 
                             ifelse(grepl("moderate delay",text, ignore.case = TRUE), 2, 
                                    ifelse(grepl("severe delay",text, ignore.case = TRUE), 3, 0))))

# Things are a bit tricky here, because red line has very different 
# different meaning of southbound/northbound ~ inbound/outbound trains
# From the information online 
# Red Line:  Toward Park Street (Green Line intersection) is Inbound; away is Outbound
# http://www.boston-discovery-guide.com/boston-subway.html
# 
# Alewife -- inbound/southbound---> Park street  <--- inbound/northbound---- Braintree/Ashmont
# Alewife <--outbound/northbound--- Park street  ---outbound/southbound----> Braintree/Ashmont
# Lets make a map of stops that are northbound and southbound

# stations with inbound/outbounds, northbound/southbound
northbound_inbound <- c("Braintree", 
                        "Quincy Adams",
                        "Quincy Center",
                        "Wollaston",
                        "North Quincy",
                        "JFK/UMASS Braintree",
                        "Broadway",
                        "South Station",
                        "Downtown Crossing - to Alewife",
                        "Savin",
                        "Fields",
                        "Shawmut",
                        "Ashmont",
                        "Park")

northbound_outbound <- c("Charles",
                         "Kendal",
                         "Central",
                         "Harvard",
                         "Porter",
                         "Davis",
                         "Alewife")

# southbound_outbound <- northbound_inbound # contains same stations
# southbound_inbound <- northbound_outbound # contains same stations

# One way of thinking about it in terms of getting to features are:
# creating column for recognizing train station where delay is been tweeted
red_line_alert <- red_line_alert %>% 
    mutate(text_clone = text) %>% 
    separate(text_clone, into = c("before_at", "after_at"), sep=" at ") %>% 
    mutate(after_at = str_trim(gsub("#mbta|Station|Ave|Street|[.]", "", after_at, ignore.case = TRUE))) %>% 
    rowwise() %>% 
    mutate( after_at = ifelse(!is.na(after_at),
                              ifelse(bounded != "", 
                                     ifelse(length(agrep(after_at, northbound_inbound, ignore.case = TRUE, value = TRUE,max =6))>0 & bounded == "northbound",
                                            paste(after_at, "inbound"),
                                            ifelse(length(agrep(after_at, northbound_inbound, ignore.case = TRUE,max =6))>0 & bounded == "southbound",
                                                   paste(after_at, "outbound"),
                                                   after_at
                                            )
                                     )
                                     , 
                                     ifelse(length(agrep(after_at, northbound_outbound, ignore.case = TRUE, value = TRUE,max =6))>0 & bounded == "northbound",
                                            paste(after_at, "outbound"),
                                            ifelse(length(agrep(after_at, northbound_outbound, ignore.case = TRUE, value = TRUE, max =6))>0 & bounded == "southbound",
                                                   paste(after_at, "inbound"),
                                                   after_at
                                            )
                                     ))
                              , after_at),
            after_at_name_code = 
                ifelse(!is.na(after_at),
                       toString(agrep(after_at, stop_names_codes$stop_code_name, value = TRUE, ignore.case = TRUE)), '')) %>%
    ungroup() %>%
    select(-after_at, -before_at) %>% 
    rename(alerts_at_station_code = after_at_name_code) 

#################################
# Green line 
#################################

# To relate to a data we already have is to add 
# these tweets as "arrival date" ~ "created" and then join them.
green_line_alert <- green_line_alert %>% 
  filter(created > startTime) %>%
  arrange(created) %>% 
  select(text, created, favoriteCount, retweetCount) %>% 
  mutate(arr_dt = created)
green_line_alert


# if severity increases with delay time or
# time series of severity increasing in the north/south bound trains
green_line_alert <- green_line_alert %>% 
  mutate(severity = ifelse(grepl("minor",text, ignore.case = TRUE), 1, 
                           ifelse(grepl("moderate",text, ignore.case = TRUE), 2, 
                                  ifelse(grepl("severe",text, ignore.case = TRUE), 3, 0))))

# Which green line is the alert from?
green_line_alert$greenLine <- str_extract(green_line_alert$text, "#GreenLine [A-z] ") %>% 
  substr(12,12)


```

asdf

```{r Visuals}
#Get data
allstops<-Tarchive_stops %>% select(stop_code, stop_name, stop_lat, stop_lon) %>% 
  filter(is.na(stop_code)==FALSE) %>% mutate(from_stop=stop_code,to_stop=stop_code)
travel_times$from_stop <- as.integer(travel_times$from_stop)
travel_times$to_stop <- as.integer(travel_times$to_stop)

#Merge latitude and longitude values
dataset<-travel_times %>% 
  left_join(allstops,by="from_stop") %>% select(-stop_code,-to_stop.y) %>%
  rename(to_stop=to_stop.x, start_stop=stop_name, start_lat=stop_lat, start_long=stop_lon)

dataset<-dataset %>% 
  left_join(allstops,by="to_stop") %>% 
  select(-stop_code,-from_stop.y) %>%
  rename(end_stop=stop_name, end_lat=stop_lat, end_long=stop_lon, from_stop=from_stop.x)

t.lub <- ymd_hms(dataset$dep_dt)
dataset$time <- round((hour(t.lub) + minute(t.lub)/60), digits=2)

#Weather data (not using it but its here)
weather<-weather %>% 
  filter(DATE>20160124,STATION_NAME=="BOSTON LOGAN INTERNATIONAL AIRPORT MA US") %>%
  select(DATE,PRCP,SNOW) %>% rename(precipitation=PRCP,snowfall=SNOW)

#RedLine
Red <-  RedLineRoute$stop[[1]] %>%
  select(stop_order, stop_id, stop_name, stop_lat, stop_lon)
Red$stop_lat<-as.numeric(Red$stop_lat)
Red$stop_lon<-as.numeric(Red$stop_lon)
Red<-Red %>% mutate(line="Red")

#GreenBLine
GreenB <-  GreenBLineRoute$stop[[1]] %>%
  select(stop_order, stop_id, stop_name, stop_lat, stop_lon)
GreenB$stop_lat<-as.numeric(GreenB$stop_lat)
GreenB$stop_lon<-as.numeric(GreenB$stop_lon)
GreenB<-GreenB %>% mutate(line="GreenB")

#GreenCLine
GreenC <-  GreenCLineRoute$stop[[1]] %>%
  select(stop_order, stop_id, stop_name, stop_lat, stop_lon)
GreenC$stop_lat<-as.numeric(GreenC$stop_lat)
GreenC$stop_lon<-as.numeric(GreenC$stop_lon)
GreenC<-GreenC %>% mutate(line="GreenC")

#GreenDLine
GreenD <-  GreenDLineRoute$stop[[1]] %>%
  select(stop_order, stop_id, stop_name, stop_lat, stop_lon)
GreenD$stop_lat<-as.numeric(GreenD$stop_lat)
GreenD$stop_lon<-as.numeric(GreenD$stop_lon)
GreenD<-GreenD %>% mutate(line="GreenD")

#GreenELine
GreenE <-  GreenELineRoute$stop[[1]] %>%
  select(stop_order, stop_id, stop_name, stop_lat, stop_lon)
GreenE$stop_lat<-as.numeric(GreenE$stop_lat)
GreenE$stop_lon<-as.numeric(GreenE$stop_lon)
GreenE<-GreenE %>% mutate(line="GreenE")

#OrangeLine
Orange <-  OrangeLineRoute$stop[[1]] %>%
  select(stop_order, stop_id, stop_name, stop_lat, stop_lon)
Orange$stop_lat<-as.numeric(Orange$stop_lat)
Orange$stop_lon<-as.numeric(Orange$stop_lon)
Orange<-Orange %>% mutate(line="Orange")

#BlueLine
Blue <-  BlueLineRoute$stop[[1]] %>%
  select(stop_order, stop_id, stop_name, stop_lat, stop_lon)
Blue$stop_lat<-as.numeric(Blue$stop_lat)
Blue$stop_lon<-as.numeric(Blue$stop_lon)
Blue<-Blue %>% mutate(line="Blue")

all_lines<-rbind(Red,GreenB,GreenC,GreenD,GreenE,Orange,Blue)
all_lines$stop_lat<-as.numeric(all_lines$stop_lat)
all_lines$stop_lon<-as.numeric(all_lines$stop_lon)

all_lines <- all_lines %>% 
  separate(stop_name, into = c("stop_name", "extra"), sep="-", fill="right") %>%
  select(-extra)


## Twitter analysis ~ for green line
## Getting actaul stop names for Greenline stops
greenB_stop_names_codes <- GreenB %>% 
  select(stop_id, stop_name) %>% 
  unite(stop_code_name, stop_id, stop_name)

greenC_stop_names_codes <- GreenC %>% 
  select(stop_id, stop_name) %>% 
  unite(stop_code_name, stop_id, stop_name)

greenD_stop_names_codes <- GreenD %>% 
  select(stop_id, stop_name) %>% 
  unite(stop_code_name, stop_id, stop_name)

greenE_stop_names_codes <- GreenE %>% 
  select(stop_id, stop_name) %>% 
  unite(stop_code_name, stop_id, stop_name)

### creating column for recognizing train station where delay is been tweeted ~ green line
green_line_alert <- green_line_alert %>% 
  mutate(text_clone = text) %>% 
  separate(text_clone, into = c("before_at", "after_at"), sep=" at ") %>% 
  mutate(after_at = str_trim(gsub("#mbta|Station|Ave|Street|[.]", "", after_at, ignore.case = TRUE))) %>% 
  rowwise() %>% 
  mutate(after_at_name_code = 
           ifelse(!is.na(after_at) & !is.na(greenLine) & greenLine == "B",
                  toString(agrep(after_at, greenB_stop_names_codes$stop_code_name, value = TRUE, ignore.case = TRUE)), 
                  ifelse(!is.na(after_at) & !is.na(greenLine) & greenLine == 'C',
                         toString(agrep(after_at, greenC_stop_names_codes$stop_code_name, value = TRUE, ignore.case = TRUE)),
                         ifelse(!is.na(after_at) & !is.na(greenLine) & greenLine == 'D',
                                toString(agrep(after_at, greenD_stop_names_codes$stop_code_name, value = TRUE, ignore.case = TRUE)),
                                ifelse(!is.na(after_at) & !is.na(greenLine) & greenLine == 'E',
                                       toString(agrep(after_at, greenD_stop_names_codes$stop_code_name, value = TRUE, ignore.case = TRUE)),
                                       ''
                                       )
                         )
                  )
           )
  ) %>% 
  ungroup() %>% 
  select(-after_at, -before_at) %>% 
  rename(alerts_at_station_code = after_at_name_code)

#Map of Boston
lon_range <- extendrange(dataset$end_long)
lat_range <- extendrange(dataset$end_lat)

gc <- geocode("boston massachusetts")
map <- get_map(gc,maptype = "toner-lite",calc_zoom(lon_range, lat_range))

ggmap(map)+
  geom_path(data=Red,aes(x=stop_lon,y=stop_lat),color="red",size=1)+
  geom_path(data=GreenB,aes(x=stop_lon,y=stop_lat),color="green",size=1)+
  geom_path(data=GreenC,aes(x=stop_lon,y=stop_lat),color="green",size=1)+
  geom_path(data=GreenD,aes(x=stop_lon,y=stop_lat),color="green",size=1)+
  geom_path(data=GreenE,aes(x=stop_lon,y=stop_lat),color="green",size=1)+
  geom_path(data=Orange,aes(x=stop_lon,y=stop_lat),color="orange",size=1)+
  geom_path(data=Blue,aes(x=stop_lon,y=stop_lat),color="blue",size=1)+
  geom_point(data=Red,aes(x=stop_lon,y=stop_lat),color="black",size=0.5)+
  geom_point(data=GreenB,aes(x=stop_lon,y=stop_lat),color="black",size=0.5)+
  geom_point(data=GreenC,aes(x=stop_lon,y=stop_lat),color="black",size=0.5)+
  geom_point(data=GreenD,aes(x=stop_lon,y=stop_lat),color="black",size=0.5)+
  geom_point(data=GreenE,aes(x=stop_lon,y=stop_lat),color="black",size=0.5)+
  geom_point(data=Orange,aes(x=stop_lon,y=stop_lat),color="black",size=0.5)+
  geom_point(data=Blue,aes(x=stop_lon,y=stop_lat),color="black",size=0.5)+
  theme(axis.ticks = element_blank(), axis.text = element_blank(),axis.title=element_blank())

#Using Leaflet
redline<-all_lines %>% filter(line=="Red")
greenBline<-all_lines %>% filter(line=="GreenB")
greenCline<-all_lines %>% filter(line=="GreenC")
greenDline<-all_lines %>% filter(line=="GreenD")
greenEline<-all_lines %>% filter(line=="GreenE")
orangeline<-all_lines %>% filter(line=="Orange")
blueline<-all_lines %>% filter(line=="Blue")

boston <- leaflet() %>% 
  setView(lng = -71.0589, lat = 42.3601, zoom = 12) %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolylines(data=redline,~stop_lon,~stop_lat,color="red") %>%
  addPolylines(data=greenBline,~stop_lon,~stop_lat,color="springgreen") %>%
  addPolylines(data=greenCline,~stop_lon,~stop_lat,color="palegreen") %>%
  addPolylines(data=greenDline,~stop_lon,~stop_lat,color="limegreen") %>%
  addPolylines(data=greenEline,~stop_lon,~stop_lat,color="green") %>%
  addPolylines(data=orangeline,~stop_lon,~stop_lat,color="orange") %>%
  addPolylines(data=blueline,~stop_lon,~stop_lat,color="blue") %>%
  addCircleMarkers(data=redline, ~stop_lon,~stop_lat,color="red",radius=1,popup=~stop_name) %>%
  addCircleMarkers(data=greenBline,~stop_lon,~stop_lat,color="springgreen",radius=1,popup=~stop_name) %>%
  addCircleMarkers(data=greenCline,~stop_lon,~stop_lat,color="palegreen",radius=1,popup=~stop_name) %>%
  addCircleMarkers(data=greenDline,~stop_lon,~stop_lat,color="limegreen",radius=1,popup=~stop_name) %>%
  addCircleMarkers(data=greenEline,~stop_lon,~stop_lat,color="green",radius=1,popup=~stop_name) %>%
  addCircleMarkers(data=orangeline,~stop_lon,~stop_lat,color="orange",radius=1,popup=~stop_name) %>%
  addCircleMarkers(data=blueline,~stop_lon,~stop_lat,color="blue",radius=1,popup=~stop_name)
boston

#Average travel times between stops
traveltime<-dataset %>% group_by(start_stop,end_stop) %>%
  summarize(avg_traveltime=mean(travel_time_sec))

betweenstops<-dataset %>% left_join(traveltime,by=c("start_stop","end_stop")) %>%
  mutate(residualtime=avg_traveltime-travel_time_sec)

#Delay vs. hour of day plot, input using start and stop_codes
traveltimes_day<-function(fromstation,tostation){
  travel<-betweenstops %>% 
    filter(start_stop==fromstation & end_stop==tostation) %>%
    group_by(time) %>% summarize(mean(residualtime))
  
  dygraph(travel,main=c(as.character(fromstation), as.character(tostation))) %>% 
    dyAxis("y", label = "Delay in Seconds") %>%
    dyAxis("x", label="Hour of Day") %>% dyRangeSelector() %>%
    dyEvent("12.00", label="Noon", labelLoc = "bottom") %>%
    dyShading(from = "7.00", to = "9.00",color="#FFE6E6") %>%
    dyShading(from = "17.00", to = "19.00",color="#CCEBD6") }

#Examples
traveltimes_day("Park Street - to Alewife","Charles/MGH - Outbound")
traveltimes_day("Charles/MGH - Outbound","Kendall/MIT - Outbound")

#Tweets
travel_times$arr_dt<-ymd_hms(travel_times$arr_dt)
travel_times$dep_dt<-ymd_hms(travel_times$dep_dt)
red_line_alert$arr_dt<-ymd_hms(red_line_alert$arr_dt)
travel_times <- travel_times %>% full_join(red_line_alert) %>% 
  filter(is.na(severity)==FALSE)

#Station of concern from alert
regexp <- "[[:digit:]]+"
travel_times$stop_code<-as.integer(str_extract(travel_times$alerts_at_station_code, regexp))

#Get latitude and longitude values
travel_times<-travel_times %>% left_join(allstops,by="stop_code") %>%
  select(dep_dt,arr_dt,severity,stop_code,stop_name,stop_lat,stop_lon) %>%
  filter(is.na(stop_lat)==FALSE) %>% filter(is.na(stop_lon)==FALSE)

#Red line severity of alerts
leaflet(data = travel_times) %>% addTiles() %>% addProviderTiles("CartoDB.Positron") %>%
  addPolylines(data=redline,~stop_lon,~stop_lat,color="red") %>%
  addCircleMarkers(data=redline, ~stop_lon,~stop_lat,color="red",radius=1,popup=~stop_name) %>%
  addMarkers(~stop_lon, ~stop_lat, clusterOptions = markerClusterOptions())
```

### Final Analysis
asdf

```{r Debug}
#remove this when we're done asdf
ls.str()
```

